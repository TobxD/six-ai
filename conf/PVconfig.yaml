# Note: if paths start with '/', they are taken relative to the directory of main.py, otherwise it is relative to the hydra working directory

defaults:
  - _self_
  - player2: mcts_nn2
  - player1: mcts_nn2
  # - player1: random_search_winning
  # - player1: random_search_losing
  # - player1: random_nolook
  # - player2: random_nolook
  - network_conf: small
  #- network_conf: huge

general:
  board_size: 10
  mode: "play"
  # mode: "train"
  # mode: "iterate"
  # mode: "eval"

#### PLAY ####
play:
  workers: 1
  num_games: 1
  #store_path: "/data/small-100.json"
  #store_path: "/data/slow-games-1.json"
  store_path: null
  game_viewer: false
  random_color: false
  #store_path: "/data/games_gen2.1.json"
  log_pv: true

#### TRAINING ####
general_train:
  #input_model_path: "/models/small_test4.ckpt"
  input_model_path: null
  output_model_path: "/models/latest.ckpt"

data:
  train_data_path:
    [
      "/data/iteration_games/games_200-1.json",
      "/data/iteration_games/games_200-1.json",
      "/data/iteration_games/games-0.json",
      "/data/iteration_games/games-1.json",
      "/data/iteration_games/games-2.json",
      "/data/iteration_games/games-3.json",
      "/data/iteration_games/games-4.json",
      "/data/iteration_games/games-5.json",
      "/data/iteration_games/games-6.json",
      "/data/iteration_games/games-7.json",
      "/data/iteration_games/games-8.json",
      "/data/iteration_games/games-9.json",
    ]
  train_val_split: 0.9
  train_dataloader_conf:
    batch_size: 128
    num_workers: 0

train:
  run_test: false
  optimizer:
    lr: 0.001
    momentum: 0.9
    nesterov: True
    weight_decay: 0.003

pl_trainer:
  max_epochs: 2
  #progress_bar_refresh_rate: 25
  # accelerator: "auto"
  # auto_lr_find: True

#### ITERATION ####
iterate:
  model_start_path: /models/iteration_models/model-10.ckpt
  num_iterations: 1000
  # number of games to play against last model with each color (total number is twice that)
  num_evaluation_games: 20
  # percentage that has to be won at least to continue with model
  winning_threshold: 0.6
  # list of previously generated data that can be used for training
  game_data_files: [
      "/data/iteration_games/games_200-1.json",
      "/data/iteration_games/games_200-1.json",
      "/data/iteration_games/games-0.json",
      "/data/iteration_games/games-1.json",
      "/data/iteration_games/games-2.json",
      "/data/iteration_games/games-3.json",
      "/data/iteration_games/games-4.json",
      "/data/iteration_games/games-5.json",
      "/data/iteration_games/games-6.json",
      "/data/iteration_games/games-7.json",
      "/data/iteration_games/games-8.json",
      "/data/iteration_games/games-9.json",
    ]
  # number of positions that are at least used for training (if available)
  # We only use whole files and take the smallest number of past files such
  # we have at least this number of positions to train on
  num_past_train_positions: 150000

eval:
  num_evaluation_games: 20
  models:
    - player: /conf/player/mcts_nn.yaml
      path: null
    - player: /conf/player/mcts_nn.yaml
      path: /models/iteration_models/model-10.ckpt
    - player: /conf/player/mcts_nn.yaml
      path: /outputs/2024-01-02/20-23-11/model-4.ckpt
    - player: /conf/player/mcts_nn.yaml
      path: /outputs/2024-01-02/20-23-11/model-9.ckpt